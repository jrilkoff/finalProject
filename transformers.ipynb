{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Youtube\n",
    "https://www.youtube.com/watch?v=DkzbCJtFvqM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DistilBert Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0edeb26bc9ff4b56bc807dc08a7151a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/758 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd8178ab4bcc44aca0f989d06c1ffa8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "596eea2527cd4bdc93a72cba36427da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/252 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6373063da5ad4ec48cb7d9baf51a9e07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f4d892bad5144dd815e9ccc4f9a1257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline('sentiment-analysis', model='ProsusAI/finbert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'negative', 'score': 0.9683200716972351}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('Institutional owners may take dramatic actions as Hudbay Minerals Inc.s (TSE:HBM) recent 5.1% drop adds to one-year losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'ProsusAI/finbert'\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name, from_pt=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'neutral', 'score': 0.9174888730049133}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('HudBay Minerals (HBM) delivered earnings and revenue surprises of 16.67% and 19.33%, respectively , for the quarter ended September 2022. Do the numbers hold clues to what lies ahead for the stock?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer('Institutional owners may take dramatic actions as Hudbay Minerals Inc.s (TSE:HBM) recent 5.1% drop adds to one-year losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 12148, 5608, 2089, 2202, 6918, 4506, 2004, 15876, 18939, 4710, 13246, 4297, 1012, 1055, 1006, 24529, 2063, 1024, 1044, 25526, 1007, 3522, 1019, 1012, 1015, 1003, 4530, 9909, 2000, 2028, 1011, 2095, 6409, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_batch = tokenizer(\n",
    "    ['Institutional owners may take dramatic actions as Hudbay Minerals Inc.s (TSE:HBM) recent 5.1% drop adds to one-year losses',\n",
    "    'Earnings Preview: HudBay Minerals (HBM) Q3 Earnings Expected to Decline'],\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    return_tensors='tf'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: [[101, 12148, 5608, 2089, 2202, 6918, 4506, 2004, 15876, 18939, 4710, 13246, 4297, 1012, 1055, 1006, 24529, 2063, 1024, 1044, 25526, 1007, 3522, 1019, 1012, 1015, 1003, 4530, 9909, 2000, 2028, 1011, 2095, 6409, 102], [101, 16565, 19236, 1024, 15876, 18939, 4710, 13246, 1006, 1044, 25526, 1007, 1053, 2509, 16565, 3517, 2000, 6689, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "token_type_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "attention_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "for key, value in tf_batch.items():\n",
    "    print(f'{key}: {value.numpy().tolist()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning a pretrained model on custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('stock-market-news.csv')\n",
    "X = df.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:6].tolist()\n",
    "X_test = X[6:9].tolist()\n",
    "\n",
    "y_train = [0, 1, 0, 0, 1, 1]\n",
    "y_test = [1, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(X_train, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(X_test, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert these encodings into Dataset objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    y_train\n",
    "))\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(test_encodings),\n",
    "    y_test\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=({'input_ids': TensorSpec(shape=(160,), dtype=tf.int32, name=None), 'token_type_ids': TensorSpec(shape=(160,), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(160,), dtype=tf.int32, name=None)}, TensorSpec(shape=(), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer, TFTrainer, TFTrainingArguments\n",
    "\n",
    "training_args = TFTrainingArguments(\n",
    "    output_dir='./results',         # output directory\n",
    "    num_train_epochs=2,             # total number of training epochs\n",
    "    per_device_train_batch_size=4,  # batch size per device during training\n",
    "    per_device_eval_batch_size=8,   # batch size per device for evaluation\n",
    "    warmup_steps=500,               # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,              # strength of weight decay\n",
    "    # logging_dir='./logs',           # directory for storing logs\n",
    "    logging_steps=10\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with training_args.strategy.scope():\n",
    "    model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "trainer = TFTrainer(\n",
    "    model=model,                    # the instantiated transformers model to be trained\n",
    "    args=training_args,             # training arguments, defined above\n",
    "    train_dataset=train_dataset,    # training dataset\n",
    "    eval_dataset=test_dataset       # evaluation dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Finbert Example > 512 tokens, sliding window approach\n",
    "https://www.youtube.com/watch?v=WEAAs_0etJQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('ProsusAI/finbert')\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('ProsusAI/finbert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"\"\"\n",
    "Most readers would already be aware that Hudbay Minerals' (TSE:HBM) stock increased significantly by 31% over the past month. But the company's key financial indicators appear to be differing across the board and that makes us question whether or not the company's current share price momentum can be maintained. In this article, we decided to focus on Hudbay Minerals' ROE.\n",
    "\n",
    "Return on equity or ROE is a key measure used to assess how efficiently a company's management is utilizing the company's capital. Simply put, it is used to assess the profitability of a company in relation to its equity capital.\n",
    "\n",
    "See our latest analysis for Hudbay Minerals\n",
    "\n",
    "How Do You Calculate Return On Equity?\n",
    "The formula for ROE is:\n",
    "\n",
    "Return on Equity = Net Profit (from continuing operations) ÷ Shareholders' Equity\n",
    "\n",
    "So, based on the above formula, the ROE for Hudbay Minerals is:\n",
    "\n",
    "4.9% = US$77m ÷ US$1.6b (Based on the trailing twelve months to September 2022).\n",
    "\n",
    "The 'return' refers to a company's earnings over the last year. Another way to think of that is that for every CA$1 worth of equity, the company was able to earn CA$0.05 in profit.\n",
    "Why Is ROE Important For Earnings Growth?\n",
    "Thus far, we have learned that ROE measures how efficiently a company is generating its profits. Depending on how much of these profits the company reinvests or \"retains\", and how effectively it does so, we are then able to assess a company’s earnings growth potential. Assuming all else is equal, companies that have both a higher return on equity and higher profit retention are usually the ones that have a higher growth rate when compared to companies that don't have the same features.\n",
    "\n",
    "Hudbay Minerals' Earnings Growth And 4.9% ROE\n",
    "On the face of it, Hudbay Minerals' ROE is not much to talk about. A quick further study shows that the company's ROE doesn't compare favorably to the industry average of 12% either. Therefore, it might not be wrong to say that the five year net income decline of 32% seen by Hudbay Minerals was probably the result of it having a lower ROE. However, there could also be other factors causing the earnings to decline. Such as - low earnings retention or poor allocation of capital.\n",
    "\n",
    "However, when we compared Hudbay Minerals' growth with the industry we found that while the company's earnings have been shrinking, the industry has seen an earnings growth of 29% in the same period. This is quite worrisome.\n",
    "\n",
    "past-earnings-growth\n",
    "past-earnings-growth\n",
    "The basis for attaching value to a company is, to a great extent, tied to its earnings growth. What investors need to determine next is if the expected earnings growth, or the lack of it, is already built into the share price. By doing so, they will have an idea if the stock is headed into clear blue waters or if swampy waters await. If you're wondering about Hudbay Minerals''s valuation, check out this gauge of its price-to-earnings ratio, as compared to its industry.\n",
    "\n",
    "Is Hudbay Minerals Efficiently Re-investing Its Profits?\n",
    "Hudbay Minerals' low LTM (or last twelve month) payout ratio of 5.1% (implying that it retains the remaining 95% of its profits) comes as a surprise when you pair it with the shrinking earnings. This typically shouldn't be the case when a company is retaining most of its earnings. So there could be some other explanations in that regard. For example, the company's business may be deteriorating.\n",
    "\n",
    "In addition, Hudbay Minerals has been paying dividends over a period of at least ten years suggesting that keeping up dividend payments is way more important to the management even if it comes at the cost of business growth. Based on the latest analysts' estimates, we found that the company's future payout ratio over the next three years is expected to hold steady at 5.1%. However, Hudbay Minerals' future ROE is expected to decline to 0.4% despite there being not much change anticipated in the company's payout ratio.\n",
    "\n",
    "Summary\n",
    "Overall, we have mixed feelings about Hudbay Minerals. Even though it appears to be retaining most of its profits, given the low ROE, investors may not be benefitting from all that reinvestment after all. The low earnings growth suggests our theory correct. That being so, the latest industry analyst forecasts show that the analysts are expecting to see a huge improvement in the company's earnings growth rate. Are these analysts expectations based on the broad expectations for the industry, or on the company's fundamentals? Click here to be taken to our analyst's forecasts page for the company.\n",
    "\n",
    "Have feedback on this article? Concerned about the content? Get in touch with us directly. Alternatively, email editorial-team (at) simplywallst.com.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.encode_plus(txt, add_special_tokens=False)\n",
    "\n",
    "tokens.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokens['input_ids']\n",
    "attention_mask = tokens['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2087, 8141, 2052, 2525, 2022, 5204, 2008, 15876, 18939, 4710]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start = 0\n",
      "end = 512\n",
      "start = 512\n",
      "end = 1023\n"
     ]
    }
   ],
   "source": [
    "start = 0\n",
    "window_length = 512\n",
    "\n",
    "total_len = len(input_ids)\n",
    "\n",
    "loop = True\n",
    "\n",
    "while loop:\n",
    "    end = start + window_length\n",
    "    if end >= total_len:\n",
    "        loop = False\n",
    "        end = total_len\n",
    "    print(f'start = {start}')\n",
    "    print(f'end = {end}')\n",
    "    start = end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for a single < 512 window\n",
    "\n",
    "def small_text(input_ids, attention_mask):\n",
    "    \n",
    "    proba_list = []\n",
    "\n",
    "    input_dict = {\n",
    "        'input_ids' : torch.Tensor([input_ids]).long(),\n",
    "        'attention_mask' : torch.Tensor([attention_mask]).int()\n",
    "    }\n",
    "\n",
    "    outputs = model(**input_dict)\n",
    "\n",
    "    probabilities = torch.nn.functional.softmax(outputs[0], dim =-1)\n",
    "    proba_list.append(probabilities)\n",
    "\n",
    "    return proba_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def large_text(input_ids, attention_mask, total_len):\n",
    "        \n",
    "    proba_list = []\n",
    "    start = 0\n",
    "    window_length = 510\n",
    "    loop = True\n",
    "\n",
    "    while loop:\n",
    "        end = start + window_length\n",
    "        if end >= total_len:\n",
    "            loop = False\n",
    "            end = total_len\n",
    "\n",
    "        # 1 => Define the text chunk\n",
    "        input_ids_chunk = input_ids[start : end]\n",
    "        attention_mask_chunk = attention_mask[start : end]\n",
    "        \n",
    "        # 2 => Append [CLS] and [SEP]\n",
    "        input_ids_chunk = [101] + input_ids_chunk + [102]\n",
    "        attention_mask_chunk = [1] + attention_mask_chunk + [1]\n",
    "        \n",
    "        # 3 => Convert regular python list to Pytorch Tensor\n",
    "        input_dict = {\n",
    "            'input_ids' : torch.Tensor([input_ids_chunk]).long(),\n",
    "            'attention_mask' : torch.Tensor([attention_mask_chunk]).int()\n",
    "        }\n",
    "        \n",
    "        outputs = model(**input_dict)\n",
    "        \n",
    "        probabilities = torch.nn.functional.softmax(outputs[0], dim = -1)\n",
    "        proba_list.append(probabilities)\n",
    "\n",
    "        start = end\n",
    "    \n",
    "    return proba_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_tokenizer(txt):\n",
    "    tokens = tokenizer.encode_plus(txt, add_special_tokens=False)\n",
    "\n",
    "    input_ids = tokens['input_ids']\n",
    "    attention_mask = tokens['attention_mask']\n",
    "\n",
    "    return input_ids, attention_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(txt):\n",
    "    \n",
    "    input_ids, attention_mask = text_tokenizer(txt)\n",
    "\n",
    "    total_len = len(input_ids)    \n",
    "   \n",
    "    if total_len < window_length:\n",
    "        proba_list = small_text(input_ids, attention_mask)\n",
    "        return proba_list\n",
    "    \n",
    "    elif total_len >= window_length:\n",
    "        proba_list = large_text(input_ids, attention_mask, total_len)\n",
    "        return proba_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis_long(txt):\n",
    "    tokens = tokenizer.encode_plus(txt, add_special_tokens=False)\n",
    "\n",
    "    input_ids = tokens['input_ids']\n",
    "    attention_mask = tokens['attention_mask']\n",
    "\n",
    "    proba_list = []\n",
    "\n",
    "    total_len = len(input_ids)    \n",
    "    start = 0\n",
    "    window_length = 510\n",
    "    \n",
    "    if total_len < window_length:\n",
    "        proba_list = small_text(input_ids, attention_mask)\n",
    "        return proba_list\n",
    "    \n",
    "    loop = True\n",
    "\n",
    "    while loop:\n",
    "        end = start + window_length\n",
    "        if end >= total_len:\n",
    "            loop = False\n",
    "            end = total_len\n",
    "\n",
    "        # 1 => Define the text chunk\n",
    "        input_ids_chunk = input_ids[start : end]\n",
    "        attention_mask_chunk = attention_mask[start : end]\n",
    "        \n",
    "        # 2 => Append [CLS] and [SEP]\n",
    "        input_ids_chunk = [101] + input_ids_chunk + [102]\n",
    "        attention_mask_chunk = [1] + attention_mask_chunk + [1]\n",
    "        \n",
    "        # 3 => Convert regular python list to Pytorch Tensor\n",
    "        input_dict = {\n",
    "            'input_ids' : torch.Tensor([input_ids_chunk]).long(),\n",
    "            'attention_mask' : torch.Tensor([attention_mask_chunk]).int()\n",
    "        }\n",
    "        \n",
    "        outputs = model(**input_dict)\n",
    "        \n",
    "        probabilities = torch.nn.functional.softmax(outputs[0], dim = -1)\n",
    "        proba_list.append(probabilities)\n",
    "\n",
    "        start = end\n",
    "\n",
    "    return proba_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_from_proba(proba_list):\n",
    "    # 0 - positive\n",
    "    # 1 - negative\n",
    "    # 2 - neutral\n",
    "\n",
    "    with torch.no_grad():\n",
    "        stacks = torch.stack(proba_list)\n",
    "        stacks = stacks.resize(stacks.shape[0], stacks.shape[2])\n",
    "        mean = stacks.mean(dim=0)\n",
    "        sentiment = torch.argmax(mean).item()\n",
    "    return mean, stacks, sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jrilk\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\_tensor.py:760: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    }
   ],
   "source": [
    "proba_list_multi = sentiment_analysis(txt)\n",
    "mean, stk, sentiment = get_mean_from_proba(proba_list_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0484, 0.4730, 0.4786])\n",
      "tensor([[0.0937, 0.4260, 0.4804],\n",
      "        [0.0281, 0.9278, 0.0441],\n",
      "        [0.0236, 0.0652, 0.9112]])\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[0.0937, 0.4260, 0.4804]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.0281, 0.9278, 0.0441]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.0236, 0.0652, 0.9112]], grad_fn=<SoftmaxBackward0>)]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(mean)\n",
    "print(stk)\n",
    "print(sentiment)\n",
    "proba_list_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0937, 0.4260, 0.4804]],\n",
       "\n",
       "        [[0.0281, 0.9278, 0.0441]],\n",
       "\n",
       "        [[0.0236, 0.0652, 0.9112]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacks = torch.stack(proba_list_multi)\n",
    "stacks\n",
    "shape = stacks.shape\n",
    "shape\n",
    "xx = torch.reshape(stacks, (shape[0], shape[2]))\n",
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jay Alammar\n",
    "https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import torch\n",
    "import transformers as ppb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    'https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv', \n",
    "    delimiter='\\t', \n",
    "    header=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a stirring , funny and finally transporting re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apparently reassembled from the cutting room f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>they presume their audience wo n't sit still f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this is a visually stunning rumination on love...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jonathan parker 's bartleby should have been t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0  a stirring , funny and finally transporting re...  1\n",
       "1  apparently reassembled from the cutting room f...  0\n",
       "2  they presume their audience wo n't sit still f...  0\n",
       "3  this is a visually stunning rumination on love...  1\n",
       "4  jonathan parker 's bartleby should have been t...  1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a stirring , funny and finally transporting re imagining of beauty and the beast and 1930s horror films'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Pre-trained BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe7131137dd4b49bd4b651f3bde8134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jrilk\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\file_download.py:125: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\jrilk\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7511af108d8c48149bc4504572fbfdc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db5f5cfca5e9419c832f91107d0c613c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3272cb82dad4177bf278d21b6bb90cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (\n",
    "    ppb.DistilBertModel, \n",
    "    ppb.DistilBertTokenizer, \n",
    "    'distilbert-base-uncased'\n",
    ")\n",
    "\n",
    "# Non distilled BERT\n",
    "# model_class, tokenizer_class, pretrained_weights = (\n",
    "#     ppb.BertModel, \n",
    "#     ppb.BertTokenizer, \n",
    "#     'bert-base-uncased'\n",
    "# )\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #1 Preparing the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = df[0].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6920, 67)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(padded).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #1 Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6m 43.2s to run\n",
    "\n",
    "input_ids = torch.tensor(padded)  \n",
    "attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = last_hidden_states[0][:,0,:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #2 Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8445086705202313"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier score: 0.519 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "clf = DummyClassifier()\n",
    "\n",
    "scores = cross_val_score(clf, train_features, train_labels)\n",
    "print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
